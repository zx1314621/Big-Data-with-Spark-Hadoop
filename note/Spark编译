./dev/make-distribution.sh \
--name 2.6.0-cdh5.7.0  \
--tgz  \
-Pyarn -Phadoop-2.6 \
-Phive -Phive-thriftserver \
-Dhadoop.version=2.6.0-cdh5.7.0


如果在编译过程中，你看到的异常信息不是太明显/看不太懂
编译命令后 -X ，就能看到更详细的编译信息

Failed to execute goal on project spark-launcher_2.11: 
Could not resolve dependencies for project org.apache.spark:spark-launcher_2.11:jar:2.1.0: 
Could not find artifact org.apache.hadoop:hadoop-client:jar:2.6.0-cdh5.7.0 
in central (https://repo1.maven.org/maven2) -> [Help 1]

坑一：pom.xml添加：
<repository>
    <id>cloudera</id>
    <url>https://repository.cloudera.com/artifactory/cloudera-repos/</url>
</repository>

坑二：
export MAVEN_OPTS="-Xmx2g -XX:ReservedCodeCacheSize=512m -XX:MaxPermSize=512M"
注意点：
	有些同学是阿里云的机器，但是你这机器的内存可能有限的，建议你们vm至少2-4G
	VM：8G

[info] Java HotSpot(TM) 64-Bit Server VM warning: INFO: os::commit_memory(0x00000000e8f84000, 18800640, 0) failed; error='无法分配内存' (errno=12)
[info] #
[info] # There is insufficient memory for the Java Runtime Environment to continue.
[info] # Native memory allocation (malloc) failed to allocate 18800640 bytes for committing reserved memory.
[info] # An error report file with more information is saved as:
[info] # /home/hadoop/source/spark-2.1.0/hs_err_pid4764.log



坑三：
如果编译的是scala版本是2.10
./dev/change-scala-version.sh 2.10

./dev/change-scala-version.sh 2.11


坑四：
was cached in the local repository, 
resolution will not be reattempted until the update interval of nexus has elapsed or updates are forced  

1） 去仓库把 xxx.lastUpdated文件全部删除，重新执行maven命令
2） 编译命令后面 -U 


有条件的小伙伴可以使用VPN，然后再进行编译，这会顺畅很多很多

